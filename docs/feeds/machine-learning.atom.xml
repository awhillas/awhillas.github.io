<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Alexander Whillas - Machine Learning</title><link href="https://alexander.whillas.com/" rel="alternate"></link><link href="https://alexander.whillas.com/feeds/machine-learning.atom.xml" rel="self"></link><id>https://alexander.whillas.com/</id><updated>2023-08-10T00:00:00+12:00</updated><entry><title>Free Energy Principle</title><link href="https://alexander.whillas.com/free-energy-principle.html" rel="alternate"></link><published>2023-08-08T00:00:00+12:00</published><updated>2023-08-10T00:00:00+12:00</updated><author><name>Alexander Whillas</name></author><id>tag:alexander.whillas.com,2023-08-08:/free-energy-principle.html</id><summary type="html">&lt;p&gt;My understanding of the Free Energy Principle and how it applies to (machine) learning agents.&lt;/p&gt;</summary><content type="html">&lt;h2&gt;The basics&lt;/h2&gt;
&lt;p&gt;&lt;img alt="Free Energy Principle, Basic outline" src="https://alexander.whillas.com/images/fep_simple.png" /&gt;&lt;/p&gt;
&lt;p&gt;So the Free Energy Principle (FEP) is a sort of universals objective function for cognitive agents i.e. agents with some sort of cognition or internal world representation that learns. It learns from sensory input and some actions that it can enact on the world.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;table class="highlighttable"&gt;&lt;tr&gt;&lt;td class="linenos"&gt;&lt;div class="linenodiv"&gt;&lt;pre&gt;&lt;span class="normal"&gt;1&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;div&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;Sensation&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Internal&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Actions&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;World&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;changes&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Sensations&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;...&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;etc&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/div&gt;

&lt;p&gt;Its a feedback loop. What they are calling free energy is the difference between the predicted (by the model) sensor(s) state and the actual sensor(s) state. The system tires to minimise this difference, or &amp;ldquo;free energy&amp;rdquo;, or entropy, or &amp;ldquo;surprise&amp;rdquo; as its call in relation to the FEP by ether updating its model or by using actions on the world, or both.&lt;/p&gt;
&lt;h2&gt;But&amp;hellip;&lt;/h2&gt;
&lt;p&gt;How does it decide which?
How do you give it an objective like walk, do the laundry or make money on the stock market?&lt;/p&gt;
&lt;p&gt;I feel like this feedback loop should give the agent the greatest self control possible, but something else is missing to give it higher order objectives.&lt;/p&gt;
&lt;h2&gt;My RoboCup Experience&lt;/h2&gt;
&lt;p&gt;&lt;img alt="Robocup Standard Platform league" src="https://alexander.whillas.com/images/robocup.png" /&gt;&lt;/p&gt;
&lt;p&gt;So I was vaguely involved in the &lt;a href="https://www.robocup.org/"&gt;RoboCup&lt;/a&gt;&lt;sup id="fnref:robocup"&gt;&lt;a class="footnote-ref" href="#fn:robocup"&gt;1&lt;/a&gt;&lt;/sup&gt; at UNSW when I was doing my masters back in 2013. The control systems on the bots then was very crude. I thought that UNSW would be using some sort of reinforcement learning (RL) to control walking but they were actually hand programming every movement.&lt;/p&gt;
&lt;p&gt;I realised there where all these sensors on the &amp;ldquo;Standard Platform&amp;rdquo; bot that we were not using and my thought at the time was that if we feed these into a feedback loop into a learning algorithm like RL&lt;sup id="fnref:notRL"&gt;&lt;a class="footnote-ref" href="#fn:notRL"&gt;2&lt;/a&gt;&lt;/sup&gt; with the objective of keeping itself upright then it might be able to learn to walk. Further more, since the robots were getting damaged, quite easily from falling over &lt;em&gt;a lot&lt;/em&gt;, individual robots might learn how to deal with their own particular damage configuration without any addition programming.&lt;/p&gt;
&lt;h2&gt;Does this lead to consciousness?&lt;/h2&gt;
&lt;p&gt;This leads to pondering if this is a system for understanding how consciousness might emerge i.e. if the system then has a model of itself in the world it is modelling, in fact, it would be hard to imagine how it would operate without it.&lt;/p&gt;
&lt;h2&gt;Feedback is the key&lt;/h2&gt;
&lt;p&gt;From my days of making experimental music/noise I know that feedback is very powerful. It was what always made the most interesting results. Here too I think the feedback mechanism is a key factoring in making this work. The system balances itself.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:robocup"&gt;
&lt;p&gt;Competition between universities to make robots play soccer. I&amp;rsquo;d really like to get my hands on a simple robot I could program and try some of these ideas out on!&amp;#160;&lt;a class="footnote-backref" href="#fnref:robocup" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:notRL"&gt;
&lt;p&gt;I would obviously say a deep neural network now.&amp;#160;&lt;a class="footnote-backref" href="#fnref:notRL" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="Machine Learning"></category></entry><entry><title>Realtime Machine Learning</title><link href="https://alexander.whillas.com/realtime-machine-learning.html" rel="alternate"></link><published>2023-04-29T00:00:00+12:00</published><updated>2023-08-08T00:00:00+12:00</updated><author><name>Alexander Whillas</name></author><id>tag:alexander.whillas.com,2023-04-29:/realtime-machine-learning.html</id><summary type="html">&lt;p&gt;Experiments in online/real-time Machine learning.&lt;/p&gt;</summary><content type="html">&lt;p&gt;In the Machine Learning Street Talk podcast&amp;rsquo;s episode on &amp;lsquo;Consciousness In The &lt;a href="https://www.wikiwand.com/en/Chinese_room"&gt;Chinese Room&lt;/a&gt;&amp;rsquo;, Francois Chollet&amp;rsquo;s &lt;a href="https://youtu.be/_KVAzAzO5HU?t=979"&gt;criticism of the thought experiment&lt;/a&gt; struck me&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;of course the person executing the rules does not understand Chinese, that&amp;rsquo;s not where you would expect understanding to be located in the system. Understanding is an imagined property of the information processing system as a whole. Understanding is not in the instructions themselves it&amp;rsquo;s not in the processor that executes the instructions it&amp;rsquo;s in the functional dynamics of how the input information is being processed by the instructions.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;He goes on to say that he believes the Chinese Room does not understand even if you are looking at the information processing system as a whole its because the book is static, or a crystallized skill, it can not adapt to changing circumstances&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;skill at a task is not sufficient to assert understanding of a task&amp;hellip; intelligence is characterized by the ability to learn and adapt and efficiently pick up new skills from experience&lt;/p&gt;
&lt;p&gt;If you understand what you&amp;rsquo;re doing then you can adapt what you&amp;rsquo;re doing when the world changes you can learn and adapt and improve and if you don&amp;rsquo;t understand what you&amp;rsquo;re doing then you&amp;rsquo;re stuck with a static skill and that&amp;rsquo;s really how you tell the difference between understanding and not understanding&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This made me think of what used to be called &amp;ldquo;online learning&amp;rdquo; or real-time learning&lt;sup id="fnref:online"&gt;&lt;a class="footnote-ref" href="#fn:online"&gt;1&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;So now I&amp;rsquo;m interested in doing some experiments with basic simulations, with neural networks that update their weights in real time and see where that leads. This is why I&amp;rsquo;m &lt;a href="https://alexander.whillas.com/a-new-hope.html"&gt;learning Rust&lt;/a&gt; incidentally.&lt;/p&gt;
&lt;h2&gt;Predator and Prey&lt;/h2&gt;
&lt;p&gt;The first experiment I&amp;rsquo;m going to try is a simple hunter-prey simulation like this&lt;/p&gt;
&lt;iframe width="560" height="315" src="https://www.youtube.com/embed/tVNoetVLuQg" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen&gt;&lt;/iframe&gt;

&lt;p&gt;What &lt;a href="https://www.youtube.com/@PezzzasWork"&gt;Pezzza&lt;/a&gt; is doing here is to take a fixed architecture neural network (NN) with input from a visual field, lines that trace out from the agent and detect the presence of ether friend or foe, and fully connect them to two outputs: speed and direction.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Pezzza's agent Neural Network" src="https://alexander.whillas.com/images/Pezzzas_NN.png" /&gt;&lt;/p&gt;
&lt;p&gt;Then, instead of using backpropagation to tune the NN&amp;rsquo;s weights he is choosing them randomly and letting natural selection kill off the bad ones&lt;sup id="fnref:mutation"&gt;&lt;a class="footnote-ref" href="#fn:mutation"&gt;2&lt;/a&gt;&lt;/sup&gt; while the ones that survive long enough to multiply propagate. This allows him to train a NN without an objective function.&lt;/p&gt;
&lt;p&gt;I want to take this basic setup and introduce real-time learning via backpropagation (BP). The problem with BP is that you need an objective function, which says how to update the weights. Its not obvious how to do this in this setup where the output is not the same as the objective function. This is where Reinforcement Learning traditionally.&lt;/p&gt;
&lt;p&gt;There is also &lt;a href="https://www.reddit.com/r/bevy/comments/1464kcq/i_built_a_self_driving_car_ai_using_rust_and_bevy/"&gt;this very similar approch&lt;/a&gt;, in &lt;a href="https://github.com/bones-ai/rust-drive-ai"&gt;Rust and using the Bevy framework&lt;/a&gt; which is exactly where I wanted to go with it.
&lt;a href="https://www.youtube.com/watch?v=H7RWcNgE-6s&amp;amp;t=1s&amp;amp;ab_channel=BonesAI"&gt;AI learns to play retro game road fighter (Reinforcement learning)&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;In search of an objective&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://www.deepmind.com/blog/alphazero-shedding-new-light-on-chess-shogi-and-go"&gt;AlphaZero&lt;/a&gt; they seem to have trained a NN to rate chess board positions without the needing of an immediate objective, sort of.&lt;/p&gt;
&lt;p&gt;From the paper &lt;a href="https://arxiv.org/pdf/1712.01815.pdf"&gt;Mastering Chess and Shogi by Self-Play with a General Reinforcement Learning Algorithm&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The &lt;a href="https://alexander.whillas.com/free-energy-principle.html"&gt;Free Energy Principle&lt;/a&gt; seems to solve this problem by making the model try to predict the next sensor readings and minimising the difference between these predictions and the actual model state at the next time step. The model can also choose actions that it needs to predict the change in environment from. But how does it choose the action? Predicting the environment is key here but how does one steer the model to perform survival actions?&lt;/p&gt;
&lt;h2&gt;Predictive Models&lt;/h2&gt;
&lt;p&gt;&lt;a href="http://blog.piekniewski.info/"&gt;Filip Piekniewski&lt;/a&gt; has this idea of &lt;a href="http://blog.piekniewski.info/2016/11/04/predictive-vision-in-a-nutshell/"&gt;predictive vision models&lt;/a&gt; which basically try to guess the next frame of video and there by model the world. One might look at this as the &lt;a href="https://en.wikipedia.org/wiki/Language_model"&gt;language modelling&lt;/a&gt; task of vision. He&amp;rsquo;s also suggesting adding online learning to this mix so the model trains and predicts at the same time, thus, according to Francois Chollet&amp;rsquo;s thesis would make it adaptive and thus conscious? And he&amp;rsquo;s got feedback from top back to bottom. He carries on about &lt;a href="https://www.tutorialspoint.com/artificial_neural_network/artificial_neural_network_associate_memory.htm"&gt;Associate Memory&lt;/a&gt; which is a type of NN (I need to look into)&lt;/p&gt;
&lt;p&gt;to be continued&amp;hellip;&lt;sup id="fnref:wip"&gt;&lt;a class="footnote-ref" href="#fn:wip"&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:online"&gt;
&lt;p&gt;&amp;ldquo;Real-time&amp;rdquo; might be a better term as &amp;ldquo;online&amp;rdquo; implies the internet these days.&amp;#160;&lt;a class="footnote-backref" href="#fnref:online" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:mutation"&gt;
&lt;p&gt;Possibly he&amp;rsquo;s also mutating the offspring in order to get variation into the population. There might be crossover, the splicing of genes, by randomly selecting one of the other survivors to mate/share-genes with.&amp;#160;&lt;a class="footnote-backref" href="#fnref:mutation" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:wip"&gt;
&lt;p&gt;This whole page is a work-in-progress and is just to document, and help me work through my ideas&amp;#160;&lt;a class="footnote-backref" href="#fnref:wip" title="Jump back to footnote 3 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="Machine Learning"></category></entry></feed>